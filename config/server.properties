# This file is generated dynamically by the start-kafka.sh script
# It serves as a template for production Kafka configuration
# All environment variables will be substituted during startup

############################# Server Basics #############################
process.roles=broker,controller
node.id=${KAFKA_NODE_ID}
controller.quorum.voters=${KAFKA_CONTROLLER_QUORUM_VOTERS}

############################# Socket Server Settings #############################
listeners=${KAFKA_LISTENERS}
advertised.listeners=${KAFKA_ADVERTISED_LISTENERS}
listener.security.protocol.map=${KAFKA_LISTENER_SECURITY_PROTOCOL_MAP}
inter.broker.listener.name=${KAFKA_INTER_BROKER_LISTENER_NAME}
controller.listener.names=${KAFKA_CONTROLLER_LISTENER_NAMES}

# Socket Send/Receive Buffer Sizes
socket.send.buffer.bytes=102400
socket.receive.buffer.bytes=102400
socket.request.max.bytes=104857600

############################# SASL/SCRAM Configuration #############################
sasl.mechanism.inter.broker.protocol=${KAFKA_SASL_MECHANISM_INTER_BROKER_PROTOCOL}
sasl.enabled.mechanisms=${KAFKA_SASL_ENABLED_MECHANISMS}

# SASL for SASL_PLAINTEXT
listener.name.sasl_plaintext.scram-sha-512.sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required;
listener.name.sasl_plaintext.scram-sha-256.sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required;

############################# Authorization #############################
# Authorizer disabled - SASL authentication is still required
# To enable authorization, uncomment these lines after cluster is running:
# super.users=${KAFKA_SUPER_USERS}
# authorizer.class.name=org.apache.kafka.metadata.authorizer.StandardAuthorizer
# allow.everyone.if.no.acl.found=true

############################# Log Basics #############################
log.dirs=${KAFKA_LOG_DIRS}
num.partitions=${KAFKA_NUM_PARTITIONS}
default.replication.factor=${KAFKA_DEFAULT_REPLICATION_FACTOR}
min.insync.replicas=${KAFKA_MIN_INSYNC_REPLICAS}
auto.create.topics.enable=${KAFKA_AUTO_CREATE_TOPICS_ENABLE}

############################# Internal Topic Settings #############################
offsets.topic.replication.factor=${KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR}
transaction.state.log.replication.factor=${KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR}
transaction.state.log.min.isr=${KAFKA_TRANSACTION_STATE_LOG_MIN_ISR}

############################# Log Flush Policy #############################
# Flush messages to disk based on time or number of messages
log.flush.interval.messages=10000
log.flush.interval.ms=1000

############################# Log Retention Policy #############################
log.retention.hours=${KAFKA_LOG_RETENTION_HOURS}
log.retention.bytes=1073741824
log.segment.bytes=${KAFKA_LOG_SEGMENT_BYTES}
log.retention.check.interval.ms=${KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS}

############################# Group Coordinator Settings #############################
group.initial.rebalance.delay.ms=${KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS}

############################# Performance Tuning #############################
num.network.threads=8
num.io.threads=8
num.replica.fetchers=4
replica.fetch.min.bytes=1
replica.fetch.wait.max.ms=500
replica.high.watermark.checkpoint.interval.ms=5000
replica.lag.time.max.ms=30000

# Compression
compression.type=snappy

# Background threads
background.threads=10

############################# Cluster and Metadata #############################
metadata.log.dir=${KAFKA_LOG_DIRS}

############################# Producer/Consumer Defaults #############################
max.request.size=1048576
max.partition.fetch.bytes=1048576
fetch.max.bytes=52428800

############################# Connection Management #############################
connections.max.idle.ms=600000
max.connections.per.ip=2147483647
max.connections=2147483647

############################# Message Size Limits #############################
message.max.bytes=1048588
replica.fetch.max.bytes=1048588

